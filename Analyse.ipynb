{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import CLIPProcessor, CLIPModel, AutoTokenizer\n",
    "\n",
    "root = \"results/\"\n",
    "image_root = \"F:/train_blocks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_post_process(caption):\n",
    "    answers = []\n",
    "    \n",
    "    caps = re.split(\"CAP\\s*\\d*\\s*[:=-]\", caption)[1:]\n",
    "    for cap in caps:\n",
    "        if re.search(\"\\d{2,}\", cap):\n",
    "            continue\n",
    "        cap = cap.strip()\n",
    "        cap = re.sub(\"^[\\'\\\"]\", \"\", cap)\n",
    "        cap = re.sub(\"[\\'\\\"]$\", \"\", cap)\n",
    "        answers.append(cap)\n",
    "    return answers\n",
    "\n",
    "def record_post_process(record):\n",
    "    answers = {}\n",
    "    \n",
    "    for key, item in record.items():\n",
    "        extracted_captions = []\n",
    "        for caption in item[\"response\"]:\n",
    "            \n",
    "            extracted_captions.extend(cap_post_process(caption))\n",
    "        answers[key] = extracted_captions\n",
    "    \n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = {}\n",
    "\n",
    "for file_name in os.listdir(root):\n",
    "    file_name_capture = re.search(\"records_(\\d_[1-9]\\d?).json\", file_name)\n",
    "    if file_name_capture:\n",
    "        file_id = file_name_capture.group(1)\n",
    "        \n",
    "        with open(os.path.join(root, file_name), \"r\") as f:\n",
    "            record = record_post_process(json.load(f))\n",
    "        \n",
    "        if len(record) == 0:\n",
    "            continue\n",
    "        records[file_id] = record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/sample.json\", \"r\") as f:\n",
    "    samples = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_keys = list(samples.keys())\n",
    "records_keys = list(records.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "for key in samples_keys:\n",
    "    file_path = os.path.join(image_root, f\"{key}.png\")\n",
    "    if os.path.isfile(file_path):\n",
    "        images.append(Image.open(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:00, 4857.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[93, 82, 99, 94, 99, 93, 100, 92, 96, 98]\n",
      "[99, 75, 100, 97, 99, 95, 100, 100, 96, 97]\n",
      "[97, 70, 94, 93, 99, 99, 99, 88, 99, 99]\n",
      "[96, 84, 97, 86, 86, 98, 91, 86, 92, 92]\n",
      "[97, 86, 98, 94, 84, 88, 92, 83, 92, 92]\n",
      "[95, 82, 97, 78, 90, 90, 95, 88, 81, 85]\n",
      "[93, 94, 99, 76, 84, 98, 87, 84, 94, 95]\n",
      "[90, 91, 97, 77, 82, 92, 92, 66, 87, 90]\n",
      "[94, 79, 88, 89, 98, 96, 96, 87, 95, 87]\n",
      "[95, 93, 105, 90, 96, 93, 92, 84, 94, 93]\n",
      "[99, 94, 99, 97, 99, 92, 100, 94, 99, 92]\n",
      "[97, 93, 94, 96, 100, 84, 93, 97, 94, 96]\n",
      "[87, 79, 94, 95, 86, 77, 85, 65, 85, 98]\n",
      "[97, 94, 100, 94, 97, 94, 92, 96, 94, 96]\n",
      "[94, 86, 99, 89, 86, 97, 84, 76, 95, 96]\n",
      "[97, 87, 100, 85, 90, 94, 89, 93, 99, 98]\n",
      "[97, 80, 98, 85, 89, 98, 99, 89, 91, 98]\n",
      "[98, 90, 89, 89, 96, 98, 95, 72, 91, 92]\n",
      "[97, 92, 100, 97, 89, 96, 96, 88, 90, 96]\n",
      "[91, 88, 96, 84, 97, 95, 94, 83, 93, 93]\n",
      "[95, 94, 95, 95, 93, 94, 97, 87, 94, 94]\n",
      "[98, 83, 88, 98, 99, 99, 96, 78, 92, 97]\n",
      "[97, 92, 94, 83, 96, 95, 83, 81, 99, 96]\n",
      "[98, 91, 100, 78, 94, 96, 91, 96, 91, 94]\n",
      "[98, 94, 87, 89, 91, 100, 94, 72, 92, 86]\n",
      "[96, 87, 103, 95, 93, 97, 91, 83, 86, 94]\n",
      "[92, 94, 100, 86, 90, 90, 95, 90, 92, 94]\n",
      "[96, 90, 100, 97, 97, 93, 93, 83, 95, 90]\n",
      "[100, 86, 100, 99, 90, 91, 97, 97, 99, 93]\n",
      "[100, 89, 90, 93, 91, 92, 99, 68, 87, 91]\n",
      "[97, 98, 89, 91, 96, 98, 98, 75, 98, 97]\n",
      "[99, 94, 86, 79, 85, 96, 79, 74, 95, 93]\n",
      "[95, 97, 99, 92, 95, 96, 98, 79, 94, 87]\n",
      "[89, 91, 96, 88, 91, 92, 98, 78, 90, 95]\n",
      "[100, 97, 100, 96, 96, 88, 91, 77, 98, 99]\n",
      "[96, 95, 95, 90, 94, 98, 94, 91, 95, 99]\n",
      "[94, 93, 93, 80, 99, 96, 95, 88, 94, 89]\n",
      "[98, 95, 100, 93, 94, 97, 98, 91, 97, 89]\n",
      "[95, 77, 97, 94, 90, 96, 92, 89, 86, 93]\n",
      "[98, 88, 98, 95, 87, 95, 92, 85, 95, 96]\n",
      "[93, 92, 100, 88, 99, 93, 97, 86, 91, 93]\n",
      "[92, 91, 93, 94, 92, 90, 99, 85, 100, 94]\n",
      "[98, 93, 99, 97, 92, 92, 98, 80, 86, 92]\n",
      "[93, 92, 99, 91, 98, 96, 94, 86, 96, 93]\n",
      "[97, 94, 89, 98, 93, 93, 91, 99, 96, 100]\n",
      "[99, 92, 100, 84, 97, 99, 97, 88, 92, 95]\n",
      "[94, 98, 97, 91, 93, 98, 95, 83, 96, 96]\n",
      "[99, 94, 99, 88, 96, 97, 92, 86, 93, 99]\n",
      "[98, 93, 100, 83, 85, 94, 94, 96, 99, 90]\n",
      "[92, 84, 95, 93, 64, 93, 99, 93, 97, 91]\n",
      "[96, 100, 97, 88, 95, 95, 96, 94, 93, 95]\n",
      "[99, 91, 100, 94, 96, 93, 97, 92, 91, 98]\n",
      "[98, 88, 91, 86, 96, 96, 89, 90, 93, 78]\n",
      "[93, 88, 100, 89, 95, 94, 98, 95, 98, 95]\n",
      "[99, 92, 93, 92, 89, 90, 99, 85, 97, 97]\n",
      "[92, 95, 96, 86, 77, 95, 88, 96, 93, 96]\n",
      "[98, 97, 98, 88, 82, 86, 92, 90, 100, 97]\n",
      "[97, 86, 99, 91, 98, 89, 94, 91, 92, 87]\n",
      "[97, 95, 91, 90, 93, 95, 95, 78, 94, 93]\n",
      "[97, 87, 75, 80, 98, 97, 88, 77, 95, 78]\n",
      "[99, 94, 85, 95, 96, 89, 99, 92, 94, 99]\n",
      "[95, 88, 97, 95, 96, 88, 94, 77, 99, 95]\n",
      "[98, 97, 99, 95, 93, 99, 96, 88, 98, 94]\n",
      "[97, 92, 99, 94, 92, 88, 74, 92, 98, 96]\n",
      "[97, 86, 100, 88, 94, 94, 92, 86, 73, 80]\n",
      "[98, 90, 100, 96, 94, 86, 99, 89, 97, 98]\n",
      "[95, 95, 93, 92, 93, 82, 95, 90, 88, 86]\n",
      "[92, 91, 98, 85, 96, 91, 97, 82, 86, 98]\n",
      "[95, 96, 97, 87, 96, 97, 88, 86, 93, 97]\n",
      "[89, 86, 98, 80, 93, 79, 86, 90, 91, 90]\n",
      "[90, 93, 94, 91, 98, 98, 91, 90, 97, 99]\n",
      "[98, 90, 93, 94, 95, 82, 93, 86, 88, 92]\n",
      "[98, 92, 100, 98, 99, 83, 93, 70, 96, 96]\n",
      "[98, 88, 100, 95, 99, 91, 99, 93, 95, 96]\n",
      "[96, 93, 100, 92, 87, 87, 96, 88, 93, 97]\n",
      "[103, 81, 89, 69, 92, 96, 92, 79, 96, 97]\n",
      "[97, 89, 99, 95, 94, 95, 96, 94, 98, 98]\n",
      "[93, 81, 96, 94, 89, 88, 95, 82, 93, 91]\n",
      "[88, 89, 93, 84, 87, 98, 93, 55, 91, 94]\n",
      "[97, 90, 93, 94, 94, 96, 87, 95, 100, 87]\n",
      "[96, 91, 99, 88, 90, 90, 94, 82, 87, 84]\n",
      "[95, 95, 99, 92, 95, 91, 93, 63, 96, 90]\n",
      "[93, 89, 91, 92, 82, 97, 97, 80, 92, 98]\n",
      "[98, 89, 98, 95, 98, 99, 98, 90, 89, 94]\n",
      "[95, 92, 99, 86, 90, 84, 91, 79, 87, 83]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_captions = []\n",
    "samples_indices = []\n",
    "records_indices = []\n",
    "\n",
    "for key_idx, key in tqdm(enumerate(samples_keys)):\n",
    "    sim_record = {}\n",
    "    for record_id, record in records.items():\n",
    "        sim_record[record_id] = record.get(key, [])\n",
    "        \n",
    "    lengths = [len(value) for value in sim_record.values()]\n",
    "    print(lengths)\n",
    "    if min(lengths) < 70:\n",
    "        continue\n",
    "        \n",
    "    for record_key, captions in sim_record.items():\n",
    "        record_idx = records_keys.index(record_key)\n",
    "        all_captions.extend(captions)\n",
    "        samples_indices.extend([key_idx] * len(captions))\n",
    "        records_indices.extend([record_idx] * len(captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (143 > 77). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "valid_index = [i for i, cap in enumerate(all_captions) if len(tokenizer.tokenize(cap)) <= 75]\n",
    "valid_captions = [all_captions[i] for i in valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "\n",
    "valid_captions = [cap for i, cap in enumerate(valid_captions) if samples_indices[valid_index[i]] == sample_idx]\n",
    "inputs = processor(text=valid_captions, images=images[sample_idx], return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([946, 36])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:75] data. DefaultCPUAllocator: not enough memory: you tried to allocate 10212335616 bytes. Buy new RAM!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-176-874dfd6a13ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\transformers\\models\\clip\\modeling_clip.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, pixel_values, attention_mask, position_ids, return_loss, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1123\u001b[0m         )\n\u001b[0;32m   1124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1125\u001b[1;33m         text_outputs = self.text_model(\n\u001b[0m\u001b[0;32m   1126\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\transformers\\models\\clip\\modeling_clip.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, position_ids, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    710\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 712\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[0mbsz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\transformers\\models\\clip\\modeling_clip.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m             \u001b[0minputs_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1914\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1916\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1917\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:75] data. DefaultCPUAllocator: not enough memory: you tried to allocate 10212335616 bytes. Buy new RAM!"
     ]
    }
   ],
   "source": [
    "outpus = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[27.4078, 26.3227, 27.6466, 23.0295, 28.3662, 30.3864, 26.3013, 28.9818,\n",
       "         27.6038, 27.2792, 28.0863, 30.0600, 24.6121, 29.9932, 30.1853, 25.2311,\n",
       "         26.1103, 26.3962, 29.0061, 25.4596, 28.5840, 26.1389, 25.1561, 29.9808,\n",
       "         27.4963, 26.7984, 29.4307, 29.9260, 27.9414, 26.7837, 24.6757, 28.0544,\n",
       "         27.1940, 28.7220, 29.4552, 26.9890, 27.8348, 28.1866, 29.1882, 31.0258,\n",
       "         24.0107, 23.9212, 19.5304, 24.2615, 22.3697, 27.4316, 26.2882, 27.7116,\n",
       "         26.0907, 27.0374, 27.0597, 30.5158, 28.2198, 27.4131, 25.3951, 27.9326,\n",
       "         26.1793, 23.3211, 29.2150, 25.4633, 24.6023, 22.5715, 24.1791, 24.4786,\n",
       "         30.2361, 25.4230, 30.9019, 26.6131, 27.0803, 24.6719, 26.8904, 24.2388,\n",
       "         26.7410, 29.2321, 25.7595, 27.6169, 29.5974, 25.8043, 31.3502, 29.6236,\n",
       "         28.0659, 28.3439, 19.3412]], grad_fn=<TBackward>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits_per_image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▊                                                                           | 8/85 [03:23<32:37, 25.42s/it]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'F:/train_blocks\\\\1118.tif_52.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-ea9498c30bd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"{key}.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits_per_image\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2877\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2878\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2879\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'F:/train_blocks\\\\1118.tif_52.png'"
     ]
    }
   ],
   "source": [
    "sim_records = {}\n",
    "\n",
    "for key in tqdm(samples.keys()):\n",
    "    sim_record = {}\n",
    "    for record_id, record in records.items():\n",
    "        captions = record.get(key, [])\n",
    "        if len(captions) == 0:\n",
    "            continue\n",
    "        \n",
    "        inputs = processor(text=captions, images=image, return_tensors=\"pt\", padding=True)\n",
    "        logits = model(**inputs).logits_per_image[0].detach().numpy()\n",
    "        sorted_logits = logits[np.argsort(logits)[::-1]]\n",
    "        sim_record[record_id] = sorted_logits\n",
    "    \n",
    "    lengths = [value.shape[0] for value in sim_record.values()]\n",
    "    \n",
    "    if min(lengths) < 16:\n",
    "        continue\n",
    "        \n",
    "    sim_records[key] = sim_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31.350168, 31.025824, 30.901922, 30.515787, 30.386406, 30.236092,\n",
       "       30.185266, 30.05999 , 29.993208, 29.98081 , 29.925995, 29.623564,\n",
       "       29.597374, 29.45525 , 29.43065 , 29.232107, 29.214981, 29.188152,\n",
       "       29.006079, 28.98182 , 28.721973, 28.583952, 28.366207, 28.343855,\n",
       "       28.219797, 28.18656 , 28.086308, 28.065895, 28.054441, 27.941397,\n",
       "       27.932589, 27.834793, 27.71163 , 27.646627, 27.616869, 27.603762,\n",
       "       27.496286, 27.431639, 27.413095, 27.407822, 27.279213, 27.194002,\n",
       "       27.080276, 27.059748, 27.037437, 26.989027, 26.89038 , 26.798405,\n",
       "       26.78367 , 26.74097 , 26.613094, 26.39619 , 26.322653, 26.301308,\n",
       "       26.28823 , 26.179272, 26.138912, 26.11029 , 26.09074 , 25.8043  ,\n",
       "       25.759514, 25.46328 , 25.459604, 25.423025, 25.395092, 25.23114 ,\n",
       "       25.156092, 24.675657, 24.671854, 24.612137, 24.602262, 24.47859 ,\n",
       "       24.261518, 24.23877 , 24.179085, 24.01067 , 23.921213, 23.321102,\n",
       "       23.029516, 22.571487, 22.369669, 19.530396], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Several buildings form a diagonal line across the image, ranging in size from large to small.',\n",
       "       'Buildings are sparsely scattered across the image, the largest one stands out in the upper right corner.',\n",
       "       'The buildings in the lower half of the image form a diagonal line',\n",
       "       'Aerial view reveals an intricate assortment of buildings in diamond formation, highlighting the largest structure at the top-right corner.',\n",
       "       'A cluster of buildings, ranging from small to large sizes, are evenly distributed throughout the image.',\n",
       "       'A dominant building stands out among smaller structures in this aerial view',\n",
       "       'The organized layout of the buildings in this aerial image is accentuated by the carefully positioned small cars in the corners.',\n",
       "       'The buildings in this aerial image are arranged in a diagonal line and two small cars bookend the corners.',\n",
       "       'The buildings in this aerial image are arranged in a diagonal line while the small cars frame the bottom of the image.',\n",
       "       'Buildings are clustered in the bottom left and right corners, with a larger gap in the center of the image.',\n",
       "       'The buildings in the bottom right corner of the image form a triangle pattern.',\n",
       "       'The buildings in the bottom right of the image are grouped together, while the smaller buildings are more spread out.',\n",
       "       'The image shows an aerial view of a well-organized urban structure, with buildings and vehicles occupying defined spaces.',\n",
       "       'From the top right to bottom left, the image displays a range of varying building sizes and shapes.',\n",
       "       'The two buildings located closest to each other suggest a larger structure or settlement.',\n",
       "       'Buildings occupy the majority of the image, each with unique sizes and locations, yet together forming a discernible pattern.',\n",
       "       'The image shows several buildings of varying sizes scattered across the frame, with two small cars present in the bottom corners.',\n",
       "       'A cluster of buildings occupy the lower right quadrant, while two small cars are located on opposite corners of the image.',\n",
       "       'A cluster of buildings occupies most of the bottom-right corner, with a smaller cluster on the top-left.',\n",
       "       'Two small cars stand in opposition from opposite corners of the image, divided by various sized buildings.',\n",
       "       'The buildings in the image are located at different positions and sizes, creating a diverse urban landscape.',\n",
       "       'Two buildings form a diagonal line running from the bottom left to the top right of the image.',\n",
       "       'Rough grid pattern with two larger buildings creating a diagonal line, smaller buildings filling gaps.',\n",
       "       'An urban landscape is visible as eight buildings of varying sizes are dispersed throughout the image.',\n",
       "       'Dispersed in a diamond-shaped formation, a small arrangement of buildings is punctuated by two cars in opposing corners at the bottom of the image.',\n",
       "       'The variety of building sizes and locations in the image exemplify the complexity of urban environments.',\n",
       "       'A diagonal line of buildings runs from the bottom left to the top right, while two small cars anchor the corners.',\n",
       "       'Two small cars are positioned in opposite corners of the image, each in front of a large building.',\n",
       "       'The buildings in the image form a loose cluster, with two small cars providing additional interest in the bottom corners of the frame.',\n",
       "       'The small cars act as mere dots on the vast landscape of buildings in the image.',\n",
       "       'Cluster of buildings at bottom right.',\n",
       "       'The placement of the buildings in the image creates a balance between the left and right sides, despite their differing sizes.',\n",
       "       'The buildings are arranged in a triangle with the largest at the apex, while two small cars balance the bottom edges of the image.',\n",
       "       'Largest building in bottom right corner, surrounded by smaller ones.',\n",
       "       'The grouping of buildings appears random at first glance, but reveals a structured formation upon closer inspection.',\n",
       "       'Buildings inhabit all quadrants of the image and reveal an even distribution of both large and small structures.',\n",
       "       'The distribution of buildings creates a balance of weight and density across the image.',\n",
       "       'The buildings form a rough triangle, with the largest occupying the top and two smaller buildings at its base.',\n",
       "       'Diagonal buildings with cluster at bottom right.',\n",
       "       'Neighborhood with buildings arranged in a square pattern, two larger in opposite corners.',\n",
       "       'The buildings align in an XS shaped pattern, with smaller buildings aligning up to bigger ones.',\n",
       "       'A variety of buildings of different sizes and shapes are situated across the frame, making for a visually diverse aerial scene.',\n",
       "       'Buildings of varying sizes form a cluster in the image, with a larger building in the top right and a substantial building in the bottom left.',\n",
       "       'Buildings of varying sizes arranged in a vague diamond shape, displaced by two small cars in opposing corners of the image.',\n",
       "       'Two small cars punctuate an orderly arrangement of buildings in a diamond-shaped formation.',\n",
       "       'The lone cars in the image are small in comparison to the surrounding buildings, adding scale to the scene.',\n",
       "       'Despite the random arrangement of objects, one can still observe building placement relative to each other and distance between them.',\n",
       "       'A semi-circle of buildings on the right side of the image encloses an open space.',\n",
       "       'The buildings in the image are arranged in no particular pattern, while two small cars provide interesting background details.',\n",
       "       'The buildings and small cars in the image provide',\n",
       "       'A towering building looms above its surroundings in this urban aerial image',\n",
       "       'Parallel lines of buildings converge at the center, with two small cars adding contrast.',\n",
       "       'Small cars in opposite corners, surrounded by buildings.',\n",
       "       'The larger building to the top right dominates the image, while smaller objects cling to its periphery.',\n",
       "       'The two small cars anchor the corners of the image, while the buildings form a triangle in the center.',\n",
       "       'Diagonal buildings with separation.',\n",
       "       'A large building dominates the top right quadrant, while smaller buildings and cars occupy the rest of the space.',\n",
       "       'The buildings follow a diagonal, with smaller buildings at the corners and larger ones in the middle, connected by a road.',\n",
       "       'A diamond-shaped formation of buildings dominates the image, with the largest structure located in the top-right corner.',\n",
       "       'A large building dominates the south west corner of the image, while smaller buildings are scattered to the east.',\n",
       "       'The small cars at opposite corners serve as bookends to the dominating buildings, united by diagonal lines.',\n",
       "       'The buildings are arranged in no specific pattern or direction, creating a scattered and evenly distributed composition in the image.',\n",
       "       'The layout of the buildings resembles a rough triangle, with the large building at the top forming the apex.',\n",
       "       'Two small cars can be spotted at opposite sides of the image',\n",
       "       'Buildings diagonal, cars at opposite corners.',\n",
       "       'Two large buildings anchor a diagonal line of six buildings, with two small cars in the corners.',\n",
       "       'The two small cars appear insignificant next to the towering buildings surrounding them.',\n",
       "       'The variety of building sizes and locations in the image creates an interesting visual balance that draws attention to the smaller details of the landscape.',\n",
       "       'The small cars in both the bottom left and right corners anchor the image, while structures of varying sizes and shapes fill the middle.',\n",
       "       'From the small cars in the corners to the diagonal line of buildings, the image captures a sense of structured motion.',\n",
       "       'The buildings and cars in the image create an unorganized yet dynamic visual landscape, with no clear central focal point.',\n",
       "       'An urban landscape with various buildings and small cars scattered throughout',\n",
       "       'A triangle arrangement of buildings dominates the scene with the largest at the top.',\n",
       "       'Amidst the random arrangement, the building in the top right and the massive building in the bottom left stand out for their size.',\n",
       "       'A mix of urban and rural architecture, the buildings are randomly positioned and spaced to produce a visually engaging yet disordered scene.',\n",
       "       'A small car is dwarfed by a nearby building, while another car seems to be fleeing the busy cluster of buildings nearby.',\n",
       "       'Buildings of varying sizes and shapes are scattered throughout the image, creating an intricate and intriguing landscape.',\n",
       "       'Contrast of cars at corners, diagonal buildings in between.',\n",
       "       'Diagonal line through image connects small cars, dividing into quadrants.',\n",
       "       \"The buildings and cars create a chaotic yet intriguing visual arrangement that draws the viewer's eye across the entirety of the frame.\",\n",
       "       'Two small cars add balance to the composition, situated at the bottom corners of the triangular arrangement.',\n",
       "       'The largest building dominates the image, while a small car in the foreground contrasts its imposing presence.',\n",
       "       'a cat'], dtype='<U156')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions_array[sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8bf9eb3a004d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKmeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mniter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embedding' is not defined"
     ]
    }
   ],
   "source": [
    "kmeans = faiss.Kmeans(embedding.shape[1], 5, niter=20, verbose=True)\n",
    "kmeans.train(embedding[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(embedding.shape[1])\n",
    "index.add(embedding)\n",
    "D, I = index.search(kmeans.centroids, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['10.tif_18', '10.tif_19', '10.tif_31', '10.tif_32', '10.tif_33', '10.tif_34', '10.tif_35', '10.tif_45', '10.tif_46', '10.tif_47', '10.tif_48', '10.tif_60'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_10.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Top and bottom right buildings cluster.', 'Clustered buildings in top right and center.']\n",
      "['Mostly horizontal/vertical alignment', 'Unique damage patterns top left and center']\n",
      "['Damaged buildings in top left and center top.', 'Damaged buildings are concentrated in the top left and center top, indicating a possible cause or target of the damage.']\n",
      "['The construction sites in the center of the image are interposed by buildings in the top right and bottom right.', 'Buildings are dispersed across the image, except for one in the middle bottom where a construction site is located.']\n",
      "['Hut or tent separate in top right', 'The hut or tent in the top right stands out amidst the permanent structures, suggesting a different social or economic status.']\n"
     ]
    }
   ],
   "source": [
    "for i in range(I.shape[0]):\n",
    "    print([captions[i] for i in I[i, :]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
