{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "from src.constants import API_KEYS\n",
    "from src.utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = API_KEYS[\"cybor\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run_conversation() missing 2 required positional arguments: 'messages' and 'functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8d8fef63d069>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_conversation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: run_conversation() missing 2 required positional arguments: 'messages' and 'functions'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)\n",
    "\n",
    "\n",
    "def run_conversation(messages, functions):\n",
    "    # Step 1: send the conversation and available functions to GPT\n",
    "    messages = messages\n",
    "    functions = functions\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "    # Step 2: check if GPT wanted to call a function\n",
    "    if response_message.get(\"function_call\"):\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        fuction_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        function_response = fuction_to_call(\n",
    "            location=function_args.get(\"location\"),\n",
    "            unit=function_args.get(\"unit\"),\n",
    "        )\n",
    "\n",
    "        # Step 4: send the info on the function call and function response to GPT\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  # extend conversation with function response\n",
    "        second_response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "        return response, second_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"Assume you are Joshua, an experienced data analyst. I will give you a detailed description of objects in an image and will ask you to complete a few tasks:\n",
    "\n",
    "Description: \"There is a 256 by 256 aerial image. One building is located at x = 67 and y = 8, in the top left of the image, with a size = 5775 pixels. One building is located at x = 114 and y = 59, in the center towards the top of the image, with a size = 3185 pixels. One building is located at x = 188 and y = 83, in the top right of the image, with a size = 2565 pixels. One building is located at x = 196 and y = 239, in the bottom right of the image, with a size = 2337 pixels. One building is located at x = 188 and y = 162, in the bottom right of the image, with a size = 6160 pixels. One building is located at x = 145 and y = 207, in the center towards the bottom of the image, with a size = 8374 pixels. One building is located at x = 153 and y = 41, in the center towards the top of the image, with a size = 3120 pixels. One building is located at x = 199 and y = 2, in the top right of the image, with a size = 7884 pixels. One building is located at x = 222 and y = 60, in the top right of the image, with a size = 2300 pixels. One small car is located at x = 30 and y = 34, in the top left of the image, with a size = 182 pixels. One small car is located at x = 38 and y = 50, in the top left of the image, with a size = 168 pixels. One small car is located at x = 56 and y = 70, in the top left of the image, with a size = 240 pixels. One small car is located at x = 86 and y = 83, in the top left of the image, with a size = 288 pixels.\"\n",
    "\n",
    "Task 1: Determine spatial relations between objects. Task 2: Extract high-level spatial patterns between the objects, such as direction, clustering, dispersion, encirclement, interposition, etc. Task 3: Generate one or more independent image captions with high-level significant spatial patterns. Each starts with \"CAP\", with no longer than 32 tokens.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Assume you are Joshua, an experienced data analyst. I will give you a detailed description of objects in an image and will ask you to complete a few tasks:  Description: \"There is a 256 by 256 aerial image. One building is located at x = 67 and y = 8, in the top left of the image, with a size = 5775 pixels. One building is located at x = 114 and y = 59, in the center towards the top of the image, with a size = 3185 pixels. One building is located at x = 188 and y = 83, in the top right of the image, with a size = 2565 pixels. One building is located at x = 196 and y = 239, in the bottom right of the image, with a size = 2337 pixels. One building is located at x = 188 and y = 162, in the bottom right of the image, with a size = 6160 pixels. One building is located at x = 145 and y = 207, in the center towards the bottom of the image, with a size = 8374 pixels. One building is located at x = 153 and y = 41, in the center towards the top of the image, with a size = 3120 pixels. One building is located at x = 199 and y = 2, in the top right of the image, with a size = 7884 pixels. One building is located at x = 222 and y = 60, in the top right of the image, with a size = 2300 pixels. One small car is located at x = 30 and y = 34, in the top left of the image, with a size = 182 pixels. One small car is located at x = 38 and y = 50, in the top left of the image, with a size = 168 pixels. One small car is located at x = 56 and y = 70, in the top left of the image, with a size = 240 pixels. One small car is located at x = 86 and y = 83, in the top left of the image, with a size = 288 pixels.\"  Task 1: Determine spatial relations between objects. Task 2: Extract high-level spatial patterns between the objects, such as direction, clustering, dispersion, encirclement, interposition, etc. Task 3: Generate one or more independent image captions with high-level significant spatial patterns. Each starts with \"CAP\", with no longer than 32 tokens. '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\n",
    "    \"role\": \"user\", \n",
    "    \"content\": \"Question 1: Given two short sides of a right triangle are 5 and 10, calculate its hypotenuse. Question 2: Given two short sides of a right triangle are 6 and 7, calculate its hypotenuse\"\n",
    "}]\n",
    "\n",
    "functions = [\n",
    "        {\n",
    "            \"name\": \"get_hypotenuse\",\n",
    "            \"description\": \"Get the hypotenuse of a right triangle given its other two sides\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"a\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"List of numbers. Each element represent the length of one short leg of a right triangle\",\n",
    "                    },\n",
    "                    \"b\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"List of numbers. Each element represent the length of another short leg of a right triangle\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"a\", \"b\"],\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    ")\n",
    "response_message = response[\"choices\"][0][\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x1e183c85810> JSON: {\n",
       "  \"content\": null,\n",
       "  \"function_call\": {\n",
       "    \"arguments\": \"{\\n  \\\"a\\\": \\\"5,6\\\",\\n  \\\"b\\\": \\\"10,7\\\"\\n}\",\n",
       "    \"name\": \"get_hypotenuse\"\n",
       "  },\n",
       "  \"role\": \"assistant\"\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_path = 'H:/xview/train_labels/xView_train.geojson'\n",
    "annotations_path = \"H:/xview/annotations\"\n",
    "train_images_path = \"F:/train_images\"\n",
    "train_blocks_path = \"F:/train_blocks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results/unique_blocks_info.json\", \"r\") as f:\n",
    "    unique_blocks_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_id = '104.tif_125'\n",
    "polygons = get_polygons(unique_blocks_info[block_id], image_size=256)\n",
    "X = [poly['rectangle_coordinates'] for poly in polygons[\"polygons\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-15, 22, 44, 74],\n",
       " [162, 29, 212, 77],\n",
       " [44, -34, 177, 54],\n",
       " [228, 44, 249, 65],\n",
       " [151, 89, 163, 99],\n",
       " [140, 99, 151, 109],\n",
       " [218, 25, 232, 40],\n",
       " [135, 124, 148, 138],\n",
       " [207, 11, 226, 28],\n",
       " [140, 117, 168, 153]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_distance(array_a, array_b):\n",
    "    x_a, y_a = (array_a[0] + array_a[2]) / 2, (array_a[1] + array_a[3]) / 2\n",
    "    x_b, y_b = (array_b[0] + array_b[2]) / 2, (array_b[1] + array_b[3]) / 2\n",
    "    \n",
    "    return np.sqrt(np.square(x_a - x_b) + np.square(y_a - y_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = DBSCAN(eps=3, min_samples=2, metric=box_distance).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
